---
---
@inproceedings{Centauri,
  title = {Centauri: Enabling Efficient Scheduling for Communication-Computation Overlap in Large Model Training via Communication Partitioning},
  author = {Chen, Chang and Li, Xiuhong and Zhu, Qianchao and Duan, Jiangfei and Sun, Peng and Zhang, Xingcheng and Yang, Chao},
  booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
  publisher = {Association for Computing Machinery},
  year = {2024},
  series = {ASPLOS '24},
  award={Best Paper Award},
  award_name={Best Paper Award},
  abbr={ASPLOS},
  bibtex_show={true},
  html={https://dl.acm.org/doi/10.1145/3620666.3651379},
  selected={true}
}

@article{internlm2,
  title={Internlm2 Technical Report},
  author={Cai, Zheng and Cao, Maosong and Chen, Haojiong and Chen, Kai and Chen, Keyu and Chen, Xin and Chen, Xun and Chen, Zehui and Chen, Zhi and Chu, Pei and others},
  journal={arXiv preprint arXiv:2403.17297},
  year={2024},
  abbr={arXiv},
  bibtex_show={true},
  html={https://arxiv.org/abs/2403.17297},
  selected={true}
}


@article{internevo,
  title={InternEvo: Efficient Long-sequence Large Language Model Training via Hybrid Parallelism and Redundant Sharding},
  author={Chen, Qiaoling and Gu, Diandian and Wang, Guoteng and Chen, Xun and Xiong, YingTong and Huang, Ting and Hu, Qinghao and Jin, Xin and Wen, Yonggang and Zhang, Tianwei and others},
  journal={arXiv preprint arXiv:2401.09149},
  year={2024},
  abbr={arXiv},
  code={https://github.com/InternLM/internevo},
  html={https://arxiv.org/abs/2401.09149},
  bibtex_show={true},
  selected={true}
}

@article{AMSP,
  title={AMSP: Reducing Communication Overhead of ZeRO for Efficient LLM Training}, 
  author={Qiaoling Chen and Qinghao Hu and Guoteng Wang and Yingtong Xiong and Ting Huang and Xun Chen and Yang Gao and Hang Yan and Yonggang Wen and Tianwei Zhang and Peng Sun},
  year={2024},
  journal = {arXiv preprint arXiv:2311.00257},
  abbr={arXiv},
  html={https://arxiv.org/abs/2311.00257},
  bibtex_show={true},
  selected={true}
}

@inproceedings {Acme,
	author = {Qinghao Hu and Zhisheng Ye and Zerui Wang and Guoteng Wang and Meng Zhang and Qiaoling Chen and Peng Sun and Dahua Lin and Xiaolin Wang and Yingwei Luo and Yonggang Wen and Tianwei Zhang},
	title = {Characterization of Large Language Model Development in the Datacenter},
	booktitle = {21st USENIX Symposium on Networked Systems Design and Implementation},
	year = {2024},
	pages = {709--729},
	publisher = {USENIX Association},
	series = {NSDI '24},
  abbr={NSDI},
  html={https://arxiv.org/abs/2403.07648},
  bibtex_show={true},
  selected={true}
}

@article{UniSched,
  title={UniSched: A Unified Scheduler for Deep Learning Training Jobs with Different User Demands},
  author={Gao, Wei and Ye, Zhisheng and Sun, Peng and Zhang, Tianwei and Wen, Yonggang},
  journal={IEEE Transactions on Computers},
  year={2024},
  publisher={IEEE},
  abbr={IEEE},
  html={https://ieeexplore.ieee.org/document/10454114},
  bibtex_show={true},
  selected={true}
}

@article{loongserve,
  title={LoongServe: Efficiently Serving Long-context Large Language Models with Elastic Sequence Parallelism},
  authod={Bingyang Wu and Shengyu Liu and Yinmin Zhong and Peng Sun and Xuanzhe Liu and Xin Jin},
  journal={arXiv preprint arXiv:2404.09526},
  year={2024},
  abbr={arXiv},
  html={https://arxiv.org/abs/2404.09526},
  bibtex_show={true},
  selected={true}
}

@article{ye2024deep,
  title={Deep Learning Workload Scheduling in GPU Datacenters: A Survey},
  author={Ye, Zhisheng and Gao, Wei and Hu, Qinghao and Sun, Peng and Wang, Xiaolin and Luo, Yingwei and Zhang, Tianwei and Wen, Yonggang},
  journal={ACM Computing Surveys},
  volume={56},
  number={6},
  pages={1--38},
  year={2024},
  publisher={ACM New York, NY},
  html={https://dl.acm.org/doi/10.1145/3638757},
  code={https://github.com/S-Lab-System-Group/Awesome-DL-Scheduling-Papers},
  abbr={ACM},
  bibtex_show={true},
  selected={false}
}
 
@inproceedings{Lucid,
  title = {Lucid: A Non-intrusive, Scalable and Interpretable Scheduler for Deep Learning Training Jobs},
  author = {Hu, Qinghao and Zhang, Meng and Sun, Peng and Wen, Yonggang and Zhang, Tianwei},
  booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
  publisher = {Association for Computing Machinery},
  year = {2023},
  award={Distinguished Paper Award},
  series = {ASPLOS '23},
  award_name={Distinguished Paper Award},
  doi={10.1145/3575693.3575705},
  html={https://dl.acm.org/doi/10.1145/3575693.3575705},
  abbr={ASPLOS},
  bibtex_show={true},
  selected={true}
}

@inproceedings {Hydro,
	author = {Qinghao Hu and Zhisheng Ye and Meng Zhang and Qiaoling Chen and Peng Sun and Yonggang Wen and Tianwei Zhang},
	title = {Hydro: {Surrogate-Based} Hyperparameter Tuning Service in Datacenters},
	booktitle = {17th USENIX Symposium on Operating Systems Design and Implementation},
	year = {2023},
	pages = {757--777},
	publisher = {USENIX Association},
	series = {OSDI '23},
  html={https://www.usenix.org/conference/osdi23/presentation/hu},
  code={https://github.com/S-Lab-System-Group/Hydro},
  abbr={OSDI},
  bibtex_show={true},
  selected={true}
}

@inproceedings {Primo,
	author = {Qinghao Hu and Harsha Nori and Peng Sun and Yonggang Wen and Tianwei Zhang},
	title = {Primo: Practical {Learning-Augmented} Systems with Interpretable Models},
	booktitle = {2022 USENIX Annual Technical Conference},
	year = {2022},
	pages = {519--538},
	publisher = {USENIX Association},
  html={https://www.usenix.org/conference/atc22/presentation/hu},
	series = {{ATC} '22},
  code={https://github.com/S-Lab-System-Group/Primo},
  pdf={https://www.usenix.org/system/files/atc22-hu.pdf},
  abbr={ATC},
  bibtex_show={true},
  selected={true}
}

@ARTICLE{Astraea,
  author={Zhisheng Ye and Peng Sun and Wei Gao and Tianwei Zhang and Xiaolin Wang and Shengen Yan and Yingwei Luo},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={ASTRAEA: A Fair Deep Learning Scheduler for Multi-Tenant GPU Clusters}, 
  year={2022},
  volume={33},
  number={11},
  pages={2781-2793},
  keywords={Graphics processing units;Resource management;Training;Measurement;Deep learning;Venus;Dynamic scheduling;Distributed systems;deep learning;GPU cluster scheduling},
  doi={10.1109/TPDS.2021.3136245},
  html={https://ieeexplore.ieee.org/document/9655467},
  abbr={IEEE},
  bibtex_show={true},
  selected={false}
}
